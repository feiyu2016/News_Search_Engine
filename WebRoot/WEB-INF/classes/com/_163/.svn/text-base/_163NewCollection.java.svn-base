package com._163;

import org.htmlparser.NodeFilter;
import org.htmlparser.Parser;
import org.htmlparser.filters.AndFilter;
import org.htmlparser.filters.HasAttributeFilter;
import org.htmlparser.filters.NotFilter;
import org.htmlparser.filters.TagNameFilter;
import org.htmlparser.util.NodeList;
import org.htmlparser.util.ParserException;

import com.ParserUtil;
import com.NewCollection;

/*
 * 对新浪网的一条新闻进行数据采集
 */
public class _163NewCollection implements NewCollection{
	private Parser parser = null;   //用于分析网页的分析器。
	private ParserUtil parserUtil = new ParserUtil();
    /**
     * 对新闻URL进行解析并采集数据
     * @param url 新闻连接。
     */
    public void parser(String url) {
    	String title = ""; 			//新闻标题
    	String source = "";			//新闻来源
    	String sourceTime = "";		//新闻来源时间
    	String author = "";			//新闻作者
    	String Content = "";		//新闻内容
    	String collectTime = "";	//新闻采集时间-系统时间
    	try {
			parser = new Parser(url);
			
			//标题
    		NodeFilter titleFilter = new TagNameFilter("h1");
        	NodeList titleNodeList = (NodeList) parser.parse(titleFilter);
        	title = parserUtil.getNodeListText(titleNodeList);
        	parser.reset();		//每次获取都必须reset，不然后面获取不到数据
        	System.out.println(title);
//        	//来源
//        	NodeFilter sourceFilter = new AndFilter(new TagNameFilter("span"), new HasAttributeFilter("id", "media_name"));
//        	NodeList sourceNodeList = (NodeList) parser.parse(sourceFilter);
//        	source = parserUtil.getNodeListText(sourceNodeList);
//        	parser.reset();	
//        	System.out.println(source);
//        	//来源时间
//        	NodeFilter sourceTimeFilter = new AndFilter(new TagNameFilter("span"), new HasAttributeFilter("id", "pub_date"));
//        	NodeList sourceTimeNodeList = (NodeList) parser.parse(sourceTimeFilter);
//        	sourceTime = parserUtil.getNodeListText(sourceTimeNodeList);
//        	parser.reset();	
//        	System.out.println(sourceTime);
        	
        	//正文
        	NodeFilter ContentTimeFilter = new AndFilter(new TagNameFilter("div"), new HasAttributeFilter("id", "endText"));
        	NodeList ContentTimeNodeList = (NodeList) parser.parse(ContentTimeFilter);
        	NodeList childList = ContentTimeNodeList.elementAt(0).getChildren();
        	childList.keepAllNodesThatMatch(new NotFilter(new TagNameFilter("div")));	//去掉非正文部分
 
        	Content = parserUtil.getNodeListHTML(ContentTimeNodeList);
        	Content = ParserUtil.getPlainText(Content);
        	System.out.println(Content);
        	parser.reset();	
 
        	
		} catch (ParserException e) {
			e.printStackTrace();
		} catch (Exception e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} 
    }
    
    
    public static void main(String[] args) {
    	_163NewCollection newCollection = new _163NewCollection();
    	newCollection.parser("http://news.163.com/11/0615/12/76JDD4CI00014JB5.html");   
    }
}